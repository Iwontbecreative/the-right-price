{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import random\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(raw,encoding='utf8'):\n",
    "    '''get the nltk tokens from a text'''\n",
    "    tokens = nltk.word_tokenize(raw) #tokenize the raw UTF-8 text\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stopswords(type=\"other\"):\n",
    "    '''returns the veronis stopwords in unicode, or if any other value is passed, it returns the default nltk french stopwords'''\n",
    "    if type==\"veronis\":\n",
    "        #VERONIS STOPWORDS\n",
    "        raw_stopword_list = [\"Ap.\", \"Apr.\", \"GHz\", \"MHz\", \"USD\", \"a\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ait\", \"alors\", \"après\", \"as\", \"attendu\", \"au\", \"au-delà\", \"au-devant\", \"aucun\", \"aucune\", \"audit\", \"auprès\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\", \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autour\", \"autre\", \"autres\", \"autrui\", \"aux\", \"auxdites\", \"auxdits\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\", \"aviez\", \"avions\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"banco\", \"ben\", \"bien\", \"bé\", \"c\", \"c'\", \"c'est\", \"c'était\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-là\", \"celles\", \"celles-ci\", \"celles-là\", \"celui\", \"celui-ci\", \"celui-là\", \"celà\", \"cent\", \"cents\", \"cependant\", \"certain\", \"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-là\", \"cf.\", \"cg\", \"cgr\", \"chacun\", \"chacune\", \"chaque\", \"chez\", \"ci\", \"cinq\", \"cinquante\", \"cinquante-cinq\", \"cinquante-deux\", \"cinquante-et-un\", \"cinquante-huit\", \"cinquante-neuf\", \"cinquante-quatre\", \"cinquante-sept\", \"cinquante-six\", \"cinquante-trois\", \"cl\", \"cm\", \"cm²\", \"comme\", \"contre\", \"d\", \"d'\", \"d'après\", \"d'un\", \"d'une\", \"dans\", \"de\", \"depuis\", \"derrière\", \"des\", \"desdites\", \"desdits\", \"desquelles\", \"desquels\", \"deux\", \"devant\", \"devers\", \"dg\", \"différentes\", \"différents\", \"divers\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dl\", \"dm\", \"donc\", \"dont\", \"douze\", \"du\", \"dudit\", \"duquel\", \"durant\", \"dès\", \"déjà\", \"e\", \"eh\", \"elle\", \"elles\", \"en\", \"en-dehors\", \"encore\", \"enfin\", \"entre\", \"envers\", \"es\", \"est\", \"et\", \"eu\", \"eue\", \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eûmes\", \"eût\", \"eûtes\", \"f\", \"fait\", \"fi\", \"flac\", \"fors\", \"furent\", \"fus\", \"fusse\", \"fussent\", \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"fûmes\", \"fût\", \"fûtes\", \"g\", \"gr\", \"h\", \"ha\", \"han\", \"hein\", \"hem\", \"heu\", \"hg\", \"hl\", \"hm\", \"hm³\", \"holà\", \"hop\", \"hormis\", \"hors\", \"huit\", \"hum\", \"hé\", \"i\", \"ici\", \"il\", \"ils\", \"j\", \"j'\", \"j'ai\", \"j'avais\", \"j'étais\", \"jamais\", \"je\", \"jusqu'\", \"jusqu'au\", \"jusqu'aux\", \"jusqu'à\", \"jusque\", \"k\", \"kg\", \"km\", \"km²\", \"l\", \"l'\", \"l'autre\", \"l'on\", \"l'un\", \"l'une\", \"la\", \"laquelle\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lez\", \"lors\", \"lorsqu'\", \"lorsque\", \"lui\", \"lès\", \"m\", \"m'\", \"ma\", \"maint\", \"mainte\", \"maintes\", \"maints\", \"mais\", \"malgré\", \"me\", \"mes\", \"mg\", \"mgr\", \"mil\", \"mille\", \"milliards\", \"millions\", \"ml\", \"mm\", \"mm²\", \"moi\", \"moins\", \"mon\", \"moyennant\", \"mt\", \"m²\", \"m³\", \"même\", \"mêmes\", \"n\", \"n'avait\", \"n'y\", \"ne\", \"neuf\", \"ni\", \"non\", \"nonante\", \"nonobstant\", \"nos\", \"notre\", \"nous\", \"nul\", \"nulle\", \"nº\", \"néanmoins\", \"o\", \"octante\", \"oh\", \"on\", \"ont\", \"onze\", \"or\", \"ou\", \"outre\", \"où\", \"p\", \"par\", \"par-delà\", \"parbleu\", \"parce\", \"parmi\", \"pas\", \"passé\", \"pendant\", \"personne\", \"peu\", \"plus\", \"plus_d'un\", \"plus_d'une\", \"plusieurs\", \"pour\", \"pourquoi\", \"pourtant\", \"pourvu\", \"près\", \"puisqu'\", \"puisque\", \"q\", \"qu\", \"qu'\", \"qu'elle\", \"qu'elles\", \"qu'il\", \"qu'ils\", \"qu'on\", \"quand\", \"quant\", \"quarante\", \"quarante-cinq\", \"quarante-deux\", \"quarante-et-un\", \"quarante-huit\", \"quarante-neuf\", \"quarante-quatre\", \"quarante-sept\", \"quarante-six\", \"quarante-trois\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatre-vingt-cinq\", \"quatre-vingt-deux\", \"quatre-vingt-dix\", \"quatre-vingt-dix-huit\", \"quatre-vingt-dix-neuf\", \"quatre-vingt-dix-sept\", \"quatre-vingt-douze\", \"quatre-vingt-huit\", \"quatre-vingt-neuf\", \"quatre-vingt-onze\", \"quatre-vingt-quatorze\", \"quatre-vingt-quatre\", \"quatre-vingt-quinze\", \"quatre-vingt-seize\", \"quatre-vingt-sept\", \"quatre-vingt-six\", \"quatre-vingt-treize\", \"quatre-vingt-trois\", \"quatre-vingt-un\", \"quatre-vingt-une\", \"quatre-vingts\", \"que\", \"quel\", \"quelle\", \"quelles\", \"quelqu'\", \"quelqu'un\", \"quelqu'une\", \"quelque\", \"quelques\", \"quelques-unes\", \"quelques-uns\", \"quels\", \"qui\", \"quiconque\", \"quinze\", \"quoi\", \"quoiqu'\", \"quoique\", \"r\", \"revoici\", \"revoilà\", \"rien\", \"s\", \"s'\", \"sa\", \"sans\", \"sauf\", \"se\", \"seize\", \"selon\", \"sept\", \"septante\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\", \"serions\", \"serons\", \"seront\", \"ses\", \"si\", \"sinon\", \"six\", \"soi\", \"soient\", \"sois\", \"soit\", \"soixante\", \"soixante-cinq\", \"soixante-deux\", \"soixante-dix\", \"soixante-dix-huit\", \"soixante-dix-neuf\", \"soixante-dix-sept\", \"soixante-douze\", \"soixante-et-onze\", \"soixante-et-un\", \"soixante-et-une\", \"soixante-huit\", \"soixante-neuf\", \"soixante-quatorze\", \"soixante-quatre\", \"soixante-quinze\", \"soixante-seize\", \"soixante-sept\", \"soixante-six\", \"soixante-treize\", \"soixante-trois\", \"sommes\", \"son\", \"sont\", \"sous\", \"soyez\", \"soyons\", \"suis\", \"suite\", \"sur\", \"sus\", \"t\", \"t'\", \"ta\", \"tacatac\", \"tandis\", \"te\", \"tel\", \"telle\", \"telles\", \"tels\", \"tes\", \"toi\", \"ton\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"trente-cinq\", \"trente-deux\", \"trente-et-un\", \"trente-huit\", \"trente-neuf\", \"trente-quatre\", \"trente-sept\", \"trente-six\", \"trente-trois\", \"trois\", \"très\", \"tu\", \"u\", \"un\", \"une\", \"unes\", \"uns\", \"v\", \"vers\", \"via\", \"vingt\", \"vingt-cinq\", \"vingt-deux\", \"vingt-huit\", \"vingt-neuf\", \"vingt-quatre\", \"vingt-sept\", \"vingt-six\", \"vingt-trois\", \"vis-à-vis\", \"voici\", \"voilà\", \"vos\", \"votre\", \"vous\", \"w\", \"x\", \"y\", \"z\", \"zéro\", \"à\", \"ç'\", \"ça\", \"ès\", \"étaient\", \"étais\", \"était\", \"étant\", \"étiez\", \"étions\", \"été\", \"étée\", \"étées\", \"étés\", \"êtes\", \"être\", \"ô\"]\n",
    "    else:\n",
    "        #get French stopwords from the nltk kit\n",
    "        raw_stopword_list = stopwords.words('french') #create a list of all French stopwords\n",
    "    stopword_list = [word for word in raw_stopword_list] #make to decode the French stopwords as unicode objects rather than ascii\n",
    "    return stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_stopwords(text,stopword_list):\n",
    "    '''normalizes the words by turning them all lowercase and then filters out the stopwords'''\n",
    "    words=[w.lower() for w in text] #normalize the words in the text, making them all lowercase\n",
    "    #filtering stopwords\n",
    "    filtered_words = [] #declare an empty list to hold our filtered words\n",
    "    for word in words: #iterate over all words from the text\n",
    "        if word not in stopword_list and word.isalpha() and len(word) > 1: #only add words that are not in the French stopwords list, are alphabetic, and are more than 1 character\n",
    "            filtered_words.append(word) #add word to filter_words list if it meets the above conditions\n",
    "    filtered_words.sort() #sort filtered_words list\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_items_improved.csv', sep=',')\n",
    "data = data[data.item_price > 0]\n",
    "data = data[data.item_price < 200]\n",
    "data['rest_location'] = data['rest_location'].apply(lambda x: x.split(\"\\n\")[1].strip())\n",
    "data['rest_location'] = data['rest_location'].replace('', '0').replace('Bercy Village', '0').astype(int)\n",
    "\n",
    "data.index = np.arange(len(data.item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window = 4\n",
    "top_k = 5000\n",
    "\n",
    "def tokenize(string):\n",
    "    tokens = get_tokens(string)\n",
    "    stop_words = get_stopswords()\n",
    "    filtered_tokens = filter_stopwords(tokens,stop_words)\n",
    "    return filtered_tokens\n",
    "\n",
    "word_counter = collections.Counter()\n",
    "for example in data.item:\n",
    "    word_counter.update(tokenize(example))\n",
    "    \n",
    "vocabulary = [pair[0] for pair in word_counter.most_common(top_k)]\n",
    "idx_to_word = dict(enumerate(vocabulary))\n",
    "word_to_idx = dict(zip(idx_to_word.values(), idx_to_word.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
